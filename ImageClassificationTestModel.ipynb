{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Install stuff -------\n",
    "#!pip install --upgrade pip\n",
    "\n",
    "#!pip install opencv-python\n",
    "#!pip install tensorflow\n",
    "#!pip install numpy==1.19.5\n",
    "\n",
    "#!pip install Pillow\n",
    "#!pip install playsound\n",
    "#!pip install gTTS\n",
    "\n",
    "#!pip install matplotlib\n",
    "#!pip install pandas\n",
    "#!pip install seaborn\n",
    "\n",
    "#!pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import random\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import IPython\n",
    "from IPython.core.display import display\n",
    "\n",
    "def text2audio(mytext):    \n",
    "    myobj = gTTS(text=mytext, lang='en', slow=False)\n",
    "    myobj.save(\"./tts.mp3\")    \n",
    "    display(IPython.display.Audio(\"./tts.mp3\", autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print system info\n",
    "import sys\n",
    "print('Python: ',sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print tensor and keras version\n",
    "print('keras: ', keras.__version__)\n",
    "print('tensorflow: ', tf.__version__)\n",
    "import numpy\n",
    "print('numpy: ', numpy.version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg_file = './project/work_pose.yml'\n",
    "cfg_file = './project/home_presence.yml'\n",
    "\n",
    "#read cfg\n",
    "import yaml\n",
    "\n",
    "with open(cfg_file, \"r\") as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.CLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = cfg[\"project_name\"]\n",
    "print('project_name: ',project_name)\n",
    "print('-'*20)\n",
    "\n",
    "dir = cfg[\"dir\"]\n",
    "temp_dir = cfg[\"temp_dir\"]\n",
    "print('project_dir: ',dir)\n",
    "print('temp_dir: ',temp_dir)\n",
    "print('-'*20)\n",
    "#read from cfg file.. since url can have pwd\n",
    "src_video = cfg[\"src_video\"]\n",
    "\n",
    "labels = cfg['labels'].split(' ')\n",
    "print('labels: ',labels)\n",
    "print('label count: ',len(labels))\n",
    "print('-'*20)\n",
    "#divide width and height of image by n (reduce resolution)\n",
    "reduce_image_wh_by = cfg['reduce_image_wh_by']\n",
    "print('reduce_image_wh_by: ',reduce_image_wh_by)\n",
    "\n",
    "crop_image_from_left = cfg['crop_image_from_left']\n",
    "crop_image_from_right = cfg['crop_image_from_right']\n",
    "print('crop_image_from_left: ',crop_image_from_left)\n",
    "print('crop_image_from_right: ',crop_image_from_right)\n",
    "print('-'*20)\n",
    "model_file = cfg[\"model_file\"]\n",
    "print('model_file: ',model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = dir + project_name + \"/\"\n",
    "project_temp_dir = temp_dir + project_name + \"/\"\n",
    "print('project_dir: ',project_dir)\n",
    "print('project_temp_dir:', project_temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capture_dim():\n",
    "    cap = None\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(src_video)\n",
    "        if(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            return frame.shape\n",
    "        else:\n",
    "            return 0,0\n",
    "    finally:\n",
    "        if cap!=None:\n",
    "            cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org shape 1080, 1920\n",
    "capture_dim = get_capture_dim()\n",
    "print('org dim: ',capture_dim)\n",
    "\n",
    "img_h = capture_dim[0]\n",
    "img_w = capture_dim[1]\n",
    "\n",
    "img_h = img_h//reduce_image_wh_by\n",
    "img_w = img_w//reduce_image_wh_by\n",
    "\n",
    "print('new dim h:',img_h)\n",
    "print('new dim w:',img_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(mytext):\n",
    "    myobj = gTTS(text=mytext, lang='en', slow=False)\n",
    "    myobj.save(\"./speak.mp3\")\n",
    "    playsound(\"./speak.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(images, captions=None, cmap=None):    \n",
    "    if captions!=None:\n",
    "        print(captions)\n",
    "    \n",
    "    if len(images) > 1:\n",
    "        f, axes = plt.subplots(1, len(images), sharey=True, figsize=(4,4))\n",
    "        f.set_figwidth(15)\n",
    "        for ax,image in zip(axes, images):\n",
    "            ax.imshow(image, cmap)\n",
    "    else:\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(images[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name():\n",
    "    return 'img_'+datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "#get_file_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frames(h,w, crop=True, count=1, delay_sec=60, save=True):\n",
    "    cap = None\n",
    "    if h==0 or w==0:\n",
    "        raise Exception('h or w can not be 0')\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(src_video)\n",
    "        #cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        \n",
    "        if(cap.isOpened()):\n",
    "            for i in range(0, count):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"failed to grab frame \")\n",
    "                    #raise Exception(\"failed to grab frame \")\n",
    "                    return None, None\n",
    "\n",
    "                #print('org shape: ',frame.shape)\n",
    "                frame = cv2.resize(frame, (w,h), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if crop:\n",
    "                    if crop_image_from_left>0:\n",
    "                        new_wl = int(w*crop_image_from_left)\n",
    "                    else:\n",
    "                        new_wl = 0\n",
    "                        \n",
    "                    if crop_image_from_right>0:\n",
    "                        #crop 70% on width from right\n",
    "                        new_wr = int(w*crop_image_from_right)\n",
    "                    else:\n",
    "                        new_wr = w                    \n",
    "                        \n",
    "                    frame = frame[0:h,new_wl:new_wr]\n",
    "\n",
    "                if save:\n",
    "                    img_name = loc_unknown+\"frame_{0}.png\".format(get_file_name())\n",
    "                    cv2.imwrite(img_name, frame)\n",
    "                else:\n",
    "                    img_name = None\n",
    "\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                if count>1 and save:\n",
    "                    print('file saved: ',img_name)\n",
    "                    \n",
    "                if (i+1)!=count:\n",
    "                    #close and re-open else we will get old frame\n",
    "                    if cap != None:\n",
    "                        cap.release()\n",
    "                    #it take about 2 sec to open cam again\n",
    "                    if delay_sec>0:\n",
    "                        time.sleep(delay_sec-2) \n",
    "                    cap = cv2.VideoCapture(src_video)\n",
    "                    if(cap.isOpened()==False):\n",
    "                        print('Could not open camera!')\n",
    "                        break            \n",
    "            return frame, img_name\n",
    "        else:\n",
    "            print('Could not open camera!')\n",
    "            return None, None\n",
    "    finally:\n",
    "        if cap != None:\n",
    "            cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomColorDistortion(tf.keras.layers.Layer):\n",
    "    contrast_range=[-1.0, 1.0]\n",
    "    brightness_delta=[-50, 50]\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RandomColorDistortion, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, images, training=True):\n",
    "        if not training:\n",
    "            return images\n",
    "\n",
    "        contrast = np.random.uniform(self.contrast_range[0], self.contrast_range[1])\n",
    "        brightness = np.random.uniform(self.brightness_delta[0], self.brightness_delta[1])\n",
    "\n",
    "        #print('brightness: ',brightness, ', contrast: ',contrast)\n",
    "\n",
    "        #images = tf.image.adjust_contrast(images, contrast)\n",
    "        images = tf.image.adjust_brightness(images, brightness)\n",
    "        images = tf.clip_by_value(images, 0, 255)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)\n",
    "\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "print('model_file: ',model_file)\n",
    "\n",
    "with CustomObjectScope({'RandomColorDistortion': RandomColorDistortion}):\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    \n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('project_dir: ',project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(project_dir+'*/*.png')\n",
    "print('all img count: ',len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "#file = random.choice(all_images)\n",
    "frame, file = capture_frames(img_h,img_w, crop=True, count=1, delay_sec=0, save=False)\n",
    "\n",
    "if False:\n",
    "    frame = Image.open(file)\n",
    "    frame = asarray(frame)\n",
    "    \n",
    "if True:\n",
    "    if file!=None:\n",
    "        print('file: ', file)\n",
    "        frame = keras.preprocessing.image.load_img(file, target_size=(img_h,img_w))\n",
    "    frame = asarray(frame)\n",
    "    #frame = keras.preprocessing.image.img_to_array(frame)\n",
    "    \n",
    "plot_image([frame])\n",
    "#print('type:',type(frame))\n",
    "#print('shape:',frame.shape)\n",
    "#print('-')\n",
    "\n",
    "img_array = tf.expand_dims(frame, 0) # Create a batch\n",
    "#img_array = frame.reshape(1, 360,448,3)\n",
    "#print('shape:',img_array.shape)\n",
    "#print('-')\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print('predictions:',predictions)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print('score:',score)\n",
    "print('-')\n",
    "print('Label:',labels[np.argmax(score)],'[', round(100*np.max(score),3), '%]')\n",
    "print('-'*25)\n",
    "for l,s in zip(labels,list(score*100)):\n",
    "    print(l.rjust(10,' '),round(float(s),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
